{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb37d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import face_recognition_models\n",
    "import dlib\n",
    "import os\n",
    "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import face_recognition\n",
    "import shutil\n",
    "from sys import platform\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f1a79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set home location\n",
    "home = str(Path.home())\n",
    "\n",
    "# platform specific file folder (mac for michael, win for satyam)\n",
    "if platform == \"darwin\":\n",
    "    # OS X\n",
    "    folder=\"Documents/projects-active/facemap_production/images1674272442.9258912/\"\n",
    "elif platform == \"win32\":\n",
    "    # Windows...\n",
    "    folder=\"foobar\"\n",
    "\n",
    "folder = os.path.join(home,folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5a7d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognition_model = face_recognition_models.face_recognition_model_location()\n",
    "face_encoder = dlib.face_recognition_model_v1(face_recognition_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5795dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_68 = [162,234,93,58,172,136,149,148,152,377,378,365,397,288,323,454,389,71,63,105,66,107,336,\n",
    "                  296,334,293,301,168,197,5,4,75,97,2,326,305,33,160,158,133,153,144,362,385,387,263,373,\n",
    "                  380,61,39,37,0,267,269,291,405,314,17,84,181,78,82,13,312,308,317,14,87]\n",
    "    \n",
    "landmark_points_5_1 = [ 2, #bottom of nose tip\n",
    "                     362, #left eye towards centre\n",
    "                     263, #left eye away from centre\n",
    "                     33,  #right eye away from centre\n",
    "                     133 #right eye towards centre \n",
    "                    ]\n",
    "landmark_points_5_2 = [ 2, #bottom of nose tip\n",
    "                     263, #left eye away from centre\n",
    "                     362, #left eye towards centre\n",
    "                     133, #right eye towards centre \n",
    "                     33  #right eye away from centre\n",
    "                    ]\n",
    "\n",
    "landmark_points_5_3 = [ 263, #left eye away from centre\n",
    "                       362, #left eye towards centre\n",
    "                       33,  #right eye away from centre\n",
    "                       133, #right eye towards centre\n",
    "                        2 #bottom of nose tip \n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9f35cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.7)\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1,min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028bb5f",
   "metadata": {},
   "source": [
    "### MP + Dlib utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5accf02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlib_detection(image, hog_face_detector, display = True):\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "    output_image = image.copy()\n",
    "    imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    start = time()\n",
    "    results = hog_face_detector(imgRGB, 0)\n",
    "    end = time()\n",
    "\n",
    "    for bbox in results:\n",
    "        x1 = bbox.left()\n",
    "        y1 = bbox.top()\n",
    "        x2 = bbox.right()\n",
    "        y2 = bbox.bottom()\n",
    "        cv2.rectangle(output_image, pt1=(x1, y1), pt2=(x2, y2), color=(0, 255, 0), thickness=width//200)  \n",
    "\n",
    "    if display:\n",
    "        cv2.putText(output_image, text='Time taken: '+str(round(end - start, 2))+' Seconds.', org=(10, height//10),\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=width//700, color=(0,0,255), thickness=width//500)\n",
    "        plt.figure(figsize=[15,15])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output\");plt.axis('off');\n",
    "\n",
    "    else:\n",
    "        return output_image, results\n",
    "    \n",
    "def mp_detection(face_detection,image, display = True):\n",
    "    height, width, _ = image.shape\n",
    "    output_image =  image.copy()\n",
    "    start = time()\n",
    "    results = face_detection.process( image[:,:,::-1])\n",
    "    end = time()\n",
    "    bbox_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255),thickness=30)\n",
    "    keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),thickness=50,circle_radius=1)\n",
    "    if results.detections:\n",
    "        for face_no, face in enumerate(results.detections):\n",
    "            #mp_drawing.draw_detection(image=output_image, detection=face,bbox_drawing_spec=bbox_drawing_spec,keypoint_drawing_spec=keypoint_drawing_spec)\n",
    "            mp_drawing.draw_detection(image=output_image, detection=face,bbox_drawing_spec=bbox_drawing_spec)\n",
    "    if display:\n",
    "        cv2.putText(output_image, text='Time taken: '+str(round(end - start, 2))+' Seconds.', org=(10, height//10),\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=width//700, color=(0,0,255), thickness=width//500)\n",
    "        plt.figure(figsize=[15,15])\n",
    "        plt.subplot(121);plt.imshow( image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output\");plt.axis('off');\n",
    "\n",
    "    else:\n",
    "        return output_image, results\n",
    "    \n",
    "def mp_landmark(face_mesh,image, display = True):\n",
    "    height, width, _ = image.shape\n",
    "    output_image =  image.copy()\n",
    "    start = time()\n",
    "    results = face_mesh.process( image[:,:,::-1])\n",
    "    end = time()\n",
    "    if results.multi_face_landmarks:\n",
    "        for facial_landmarks in results.multi_face_landmarks:\n",
    "            for i in landmark_points_5_3:                    ######### CORRECTION: landmark_points_5_3 is the correct one for sure\n",
    "                pt1 = facial_landmarks.landmark[i]\n",
    "                x = int(pt1.x * width)\n",
    "                y = int(pt1.y * height)\n",
    "                cv2.circle(output_image, (x, y), 30, (0, 255, 0), -1)\n",
    "    if display:\n",
    "        cv2.putText(output_image, text='Time taken: '+str(round(end - start, 2))+' Seconds.', org=(10, height//10),\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=width//700, color=(0,0,255), thickness=width//500)\n",
    "        plt.figure(figsize=[15,15])\n",
    "        plt.subplot(121);plt.imshow( image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output\");plt.axis('off');\n",
    "    else:\n",
    "        return output_image, results\n",
    "    \n",
    "def dlib_landmark(hog_face_detector,image, display = True):\n",
    "    height, width, _ = image.shape\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_5_face_landmarks.dat\")\n",
    "    gray = cv2.cvtColor(sample_img, cv2.COLOR_BGR2GRAY)\n",
    "    output_image = sample_img.copy()\n",
    "    # detect faces in the grayscale image\n",
    "    start = time()\n",
    "    results = hog_face_detector(gray, 1)\n",
    "    end = time()\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(results):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        j=0\n",
    "        for (x, y) in shape:\n",
    "            j+=1\n",
    "            cv2.circle(output_image, (x, y), 30, (0, 0, 255), -1)\n",
    "            cv2.putText(output_image,str(j), (x, y),fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=width//1000, color=(0,0,0), thickness=width//500)\n",
    "            \n",
    "    if display:\n",
    "        cv2.putText(output_image, text='Time taken: '+str(round(end - start, 2))+' Seconds.', org=(10, height//10),\n",
    "                    fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=width//700, color=(0,0,255), thickness=width//500)\n",
    "        plt.figure(figsize=[15,15])\n",
    "        plt.subplot(121);plt.imshow( image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output\");plt.axis('off');\n",
    "    else:\n",
    "        return output_image, results\n",
    "    \n",
    "def landmark_pt_list(mesh_results,width,height):\n",
    "        ## function for return 5 landmarks in a dlib usable datatype\n",
    "\n",
    "    if mesh_results.multi_face_landmarks:\n",
    "        for i,face_landmarks in enumerate(mesh_results.multi_face_landmarks): \n",
    "            if i==0:\n",
    "                raw_landmark_set = []\n",
    "                for index in landmark_points_5_3:                       ######### CORRECTION: landmark_points_5_3 is the correct one for sure\n",
    "                    x = int(face_landmarks.landmark[index].x * width)\n",
    "                    y = int(face_landmarks.landmark[index].y * height)\n",
    "                    landmark_point=dlib.point([x,y])\n",
    "                    raw_landmark_set.append(landmark_point)\n",
    "                all_points=dlib.points(raw_landmark_set)\n",
    "#         return dlib.points([{\n",
    "#             \"nose_tip\": [raw_landmark_set[0]],\n",
    "#             \"left_eye\": raw_landmark_set[1:3],\n",
    "#             \"right_eye\": raw_landmark_set[3:],\n",
    "#             }])\n",
    "        return all_points\n",
    "\n",
    "def mp_bounding_rect(detection_results,width,height):\n",
    "        #function for returning the bounding box in a dlib usable datatype\n",
    "\n",
    "    if detection_results.detections:\n",
    "        for i,detection in enumerate(detection_results.detections):\n",
    "            if i==0:\n",
    "                # bbox data\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                xy_min = _normalized_to_pixel_coordinates(bbox.xmin, bbox.ymin, height,width)\n",
    "                xy_max = _normalized_to_pixel_coordinates(bbox.xmin + bbox.width, bbox.ymin + bbox.height,height,width)\n",
    "                if xy_min is None or xy_max is None:return\n",
    "                else:\n",
    "                    xmin,ymin =xy_min\n",
    "                    xmax,ymax = xy_max\n",
    "                    rectangle= dlib.rectangle(left=xmin, top=ymax, right=xmax, bottom=ymin)\n",
    "                    return rectangle\n",
    "                \n",
    "def ret_encoding(filepath,num_jitters=1):\n",
    "        ##function for returning the encodings\n",
    "\n",
    "    image_input = cv2.imread(filepath)\n",
    "    image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)\n",
    "    #image_input =face_recognition.load_image_file(filepath)\n",
    "    height,width=image_input.shape[:-1]           ######## CORRECTION : height and width interchanged\n",
    "    \n",
    "    mesh_results = face_mesh.process(image_input)            #### mediapipe facial landmarks\n",
    "    all_points=  landmark_pt_list(mesh_results,width,height) \n",
    "    \n",
    "    detection_results = face_detection.process(image_input) ######mediapipe face detection\n",
    "    b_box=mp_bounding_rect(detection_results,width,height)\n",
    "\n",
    "#     _,detection_results=dlib_detection(image_input, hog_face_detector, display = False) ## dlib face detection\n",
    "#     b_box=detection_results[0]\n",
    "    \n",
    "    if (all_points is None) or (b_box is None):return \n",
    "    raw_landmark_set=dlib.full_object_detection(b_box,all_points)\n",
    "    encodings=face_encoder.compute_face_descriptor(image_input, raw_landmark_set, num_jitters)\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df1a26",
   "metadata": {},
   "source": [
    "### Linear sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "577d2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file I/O\n",
    "\n",
    "def get_img_list(folder):\n",
    "    img_list=[]\n",
    "    for file in os.listdir(folder):\n",
    "        if not file.startswith('.') and os.path.isfile(os.path.join(folder, file)):\n",
    "            filepath = os.path.join(folder, file)\n",
    "            filepath=filepath.replace('\\\\' , '/')\n",
    "            img_list.append(file)\n",
    "    return img_list        \n",
    "    print(\"got image list\")\n",
    "    \n",
    "def save_sorted(folder, image, counter, dist):\n",
    "    sorted_name = \"linear_sort_\"+str(counter)+\"_\"+str(round(dist, 2))+\".jpg\"\n",
    "    sortfolder=\"sorted2\"\n",
    "    newfolder = os.path.join(folder,sortfolder)\n",
    "    old_name=os.path.join(folder,image)\n",
    "    new_name=os.path.join(newfolder,sorted_name)\n",
    "    if not os.path.exists(newfolder):\n",
    "        os.makedirs(newfolder)\n",
    "    shutil.copy(old_name, new_name)\n",
    "    print('saved, ',sorted_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65210f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distance beetween encodings\n",
    "\n",
    "def get_d(enc1, enc2):\n",
    "    enc1=np.array(enc1)\n",
    "    enc2=np.array(enc2)\n",
    "    d=np.linalg.norm(enc1 - enc2, axis=0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec3081e",
   "metadata": {},
   "source": [
    "### dataframe creation and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99858bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_list_df(folder, img_list):\n",
    "#     enc_dict={}\n",
    "    csv_name=\"face_encodings.csv\"\n",
    "    col1=\"file_name\"\n",
    "    col2=\"encoding\"\n",
    "    curr=0\n",
    "    total = len(img_list)\n",
    "\n",
    "    # encodings column list for splitting\n",
    "    col_list=[]\n",
    "    for i in range(128):\n",
    "        col_list.append(col2+str(i))\n",
    "\n",
    "    #initializing the dataframe\n",
    "    image_data=pd.DataFrame(columns=[col1, col2])\n",
    "\n",
    "    \n",
    "    for img in img_list:\n",
    "        if curr%10==0:print(curr,\"/\",total)\n",
    "        curr+=1\n",
    "        filepath = os.path.join(folder,img)        \n",
    "        filepath=filepath.replace('\\\\' , '/')  ## cv2 accepts files with \"/\" instead of \"\\\"\n",
    "        encodings=ret_encoding(filepath)\n",
    "        if encodings is not None:              ## checking if a face is found\n",
    "            data=pd.DataFrame({col1:img,col2:[np.array(encodings)]})\n",
    "            image_data = pd.concat([image_data,data],ignore_index=True)  \n",
    "\n",
    "    #splitting the encodings column\n",
    "    output_data = pd.DataFrame(image_data[col2].to_list(), columns=col_list)\n",
    "    #adding the filename column and then puting it first\n",
    "    output_data[[col1]]=pd.DataFrame(image_data[col1].tolist(),index=image_data.index)\n",
    "    clms = output_data.columns.tolist()\n",
    "    clms = clms[-1:] + clms[:-1]\n",
    "    output_data=output_data[clms]\n",
    "    # saving without index\n",
    "    output_data.to_csv(csv_name, index=False)\n",
    "    df = pd.read_csv(csv_name)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cea4dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_df(folder, start_img, df_enc):\n",
    "    if start_img == \"median\":\n",
    "        enc1 = df_enc.median().to_list()\n",
    "#         print(\"in median\")\n",
    "    else:\n",
    "#         enc1 = get 2-129 from df via stimg key\n",
    "        enc1 = df_enc.loc[start_img].to_list()\n",
    "        df_enc=df_enc.drop(start_img)\n",
    "#         print(\"in new img\",len(df_enc.index))\n",
    "    \n",
    "#     img_list.remove(start_img)\n",
    "#     enc1=enc_dict[start_img]\n",
    "    \n",
    "    dist=[]\n",
    "    dist_dict={}\n",
    "    for index, row in df_enc.iterrows():\n",
    "#         print(row['c1'], row['c2'])\n",
    "#     for img in img_list:\n",
    "        enc2 = row\n",
    "        if (enc1 is not None) and (enc2 is not None):\n",
    "            d = get_d(enc1, enc2)\n",
    "            dist.append(d)\n",
    "            dist_dict[d]=index\n",
    "    dist.sort()\n",
    "#     print(len(dist))\n",
    "    return dist[0], dist_dict[dist[0]], df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73681356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if new and old make a face\n",
    "def is_face(image):\n",
    "    # For static images:\n",
    "    # I think this list is not used\n",
    "    IMAGE_FILES = []\n",
    "    with mp_face_detection.FaceDetection(model_selection=1, \n",
    "                                        min_detection_confidence=0.6\n",
    "                                        ) as face_detection:\n",
    "        # image = cv2.imread(file)\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "#         detection_results = face_detection.process(image)\n",
    "\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        if not results.detections:\n",
    "            is_face = False\n",
    "        else:\n",
    "            is_face = True\n",
    "        # annotated_image = image.copy()\n",
    "        # for detection in results.detections:\n",
    "        #     is_face = True\n",
    "        #     print('Nose tip:')\n",
    "        #     print(mp_face_detection.get_key_point(\n",
    "        #       detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n",
    "        #     mp_drawing.draw_detection(annotated_image, detection)\n",
    "        # cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "        return is_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04ba4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if new and old make a face\n",
    "def test_pair(last_file, new_file):\n",
    "    try:\n",
    "        img = cv2.imread(new_file)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width, height)\n",
    "        print('loaded img 1')\n",
    "        \n",
    "        last_img = cv2.imread(new_file)\n",
    "        last_height, last_width, last_layers = last_img.shape\n",
    "        last_size = (last_width, last_height)\n",
    "        print('loaded img 2')\n",
    "        \n",
    "        # test to see if this is actually an face, to get rid of blank ones/bad ones\n",
    "        if is_face(img):\n",
    "            print('new file is face')\n",
    "            # if not the first image\n",
    "#             if i>0:\n",
    "            # blend this image with the last image\n",
    "            blend = cv2.addWeighted(img, 0.5, last_img, 0.5, 0.0)\n",
    "            print('blended faces')\n",
    "            blended_face = is_face(blend)\n",
    "            print('is_face ',blended_face)\n",
    "            # if blended image has a detectable face, append the img\n",
    "            if blended_face:\n",
    "#                     img_array.append(img)\n",
    "                print('is a face! adding it')\n",
    "                return True\n",
    "            else:\n",
    "                print('skipping this one')\n",
    "                return False\n",
    "            # for the first one, just add the image\n",
    "            # this may need to be refactored in case the first one is bad?\n",
    "#             else:\n",
    "#                 print('this is maybe the first round?')\n",
    "#                 img_array.append(img)\n",
    "        else:\n",
    "            print('new_file is not face: ',new_file)\n",
    "            return False\n",
    "\n",
    "#         i+=1\n",
    "\n",
    "    except:\n",
    "        print('failed:',new_file)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6543e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 610\n",
      "10 / 610\n",
      "20 / 610\n",
      "30 / 610\n",
      "40 / 610\n",
      "50 / 610\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jf/dgn0j6zj4659c4x2xfqh84xh0000gn/T/ipykernel_3740/2964707834.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# enc_dict = encode_list(folder, img_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_list_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jf/dgn0j6zj4659c4x2xfqh84xh0000gn/T/ipykernel_3740/2431275125.py\u001b[0m in \u001b[0;36mencode_list_df\u001b[0;34m(folder, img_list)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## cv2 accepts files with \"/\" instead of \"\\\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mencodings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mret_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencodings\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;31m## checking if a face is found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jf/dgn0j6zj4659c4x2xfqh84xh0000gn/T/ipykernel_3740/2007946963.py\u001b[0m in \u001b[0;36mret_encoding\u001b[0;34m(filepath, num_jitters)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m##function for returning the encodings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mimage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0mimage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;31m#image_input =face_recognition.load_image_file(filepath)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_list = get_img_list(folder)\n",
    "# start_img = img_list[1]\n",
    "start_img = \"median\"\n",
    "\n",
    "# enc_dict = encode_list(folder, img_list)\n",
    "df_enc = encode_list_df(folder, img_list)\n",
    "\n",
    "df_enc.set_index('file_name', inplace=True)\n",
    "\n",
    "# print(df_enc.median().to_list())\n",
    "\n",
    "#with lists/dicts\n",
    "# dist=0\n",
    "# for i in range(len(img_list)-1):\n",
    "#     save_sorted(folder, start_img, i, dist)\n",
    "#     dist, start_img = get_closest(folder, start_img,img_list, enc_dict)\n",
    "    \n",
    "#     print(dist)\n",
    "#     print (start_img)\n",
    "    \n",
    "#     if dist > .37: \n",
    "#         continue\n",
    "\n",
    "#with df\n",
    "dist=0\n",
    "for i in range(len(df_enc.index)-2):\n",
    "    dist, start_img, df_enc = get_closest_df(folder, start_img,df_enc)\n",
    "    if i>0:\n",
    "        #test blend\n",
    "#         last_file = os.path.join(folder,)\n",
    "        blend_is_face = (test_pair(os.path.join(folder,last_img), os.path.join(folder,start_img)))\n",
    "        print('blend_is_face ',blend_is_face)\n",
    "        if blend_is_face:\n",
    "#         print(test_pair(last_img,start_img))\n",
    "            save_sorted(folder, start_img, i, dist)\n",
    "            last_img = start_img\n",
    "#         else:\n",
    "#             start_img = last_img\n",
    "            \n",
    "    print(i)\n",
    "    print(len(df_enc.index))\n",
    "    print(dist)\n",
    "    print (start_img)\n",
    "    \n",
    "    if dist > .37: \n",
    "        break\n",
    "        \n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bd668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf856c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a4109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654606f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d801aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Env37]",
   "language": "python",
   "name": "conda-env-Env37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
